# Mortality AMI Predictor (Tools)

**Version 2.0 - Fully Modularized Architecture**

End-to-end ML project for predicting in-hospital mortality and ventricular arrhythmias in AMI patients. Features a professional, modular Python codebase, Jupyter notebooks, automated tests, and a Streamlit dashboard.

## üéâ What's New in v2.0

- ‚úÖ **Complete Modularization**: Transformed from 9 monolithic files into 10 specialized modules with 38+ focused files
- ‚úÖ **Professional Design**: Factory, Strategy, Builder, Singleton, and Adapter patterns
- ‚úÖ **Type Safety**: 100% type hints across all modules
- ‚úÖ **Extensibility**: Easy to add new models, strategies, and features via registry pattern
- ‚úÖ **Better Organization**: No file > 500 lines, average ~100 lines per file
- ‚úÖ **Comprehensive Documentation**: 4+ guides including architecture, migration, and structure docs
- ‚úÖ **New Organized Structure**: All processed data, models, and plots centralized in `processed/` directory

### üìö Documentation

- **[Quick Start Guide](src/README.md)** - Get started in 5 minutes
- **[Complete Modularization Summary](src/COMPLETE_MODULARIZATION_SUMMARY.md)** - Full overview of all modules
- **[Migration Guide](src/MIGRATION_GUIDE.md)** - How to migrate from v1.0 to v2.0
- **[Project Structure](src/PROJECT_STRUCTURE.md)** - Visual diagrams and architecture
- **[Modularization Guide](src/MODULARIZATION_GUIDE.md)** - Deep dive into design decisions

---

## üìÅ New Directory Structure (v2.1)

All processed outputs are now organized in the `processed/` directory with automatic timestamp management:

```
Tools/processed/
‚îú‚îÄ‚îÄ cleaned_datasets/              # Cleaned datasets
‚îÇ   ‚îî‚îÄ‚îÄ cleaned_dataset_YYYYMMDD_HHMMSS.csv
‚îú‚îÄ‚îÄ plots/                         # All visualizations organized by type
‚îÇ   ‚îú‚îÄ‚îÄ eda/                       # Exploratory data analysis plots
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                # Model evaluation plots
‚îÇ   ‚îú‚îÄ‚îÄ explainability/            # SHAP, PDP, permutation plots
‚îÇ   ‚îî‚îÄ‚îÄ training/                  # Learning curves, CV results
‚îú‚îÄ‚îÄ models/                        # Trained models by type
‚îÇ   ‚îú‚îÄ‚îÄ dtree/                     # Decision tree models
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_dtree_YYYYMMDD_HHMMSS.joblib
‚îÇ   ‚îú‚îÄ‚îÄ knn/                       # KNN models
‚îÇ   ‚îú‚îÄ‚îÄ xgb/                       # XGBoost models
‚îÇ   ‚îú‚îÄ‚îÄ logistic/                  # Logistic regression models
‚îÇ   ‚îú‚îÄ‚îÄ random_forest/             # Random forest models
‚îÇ   ‚îú‚îÄ‚îÄ neural_network/            # Neural network models
‚îÇ   ‚îî‚îÄ‚îÄ testsets/                  # Test and train sets
‚îÇ       ‚îú‚îÄ‚îÄ testset_dtree_YYYYMMDD_HHMMSS.parquet
‚îÇ       ‚îî‚îÄ‚îÄ trainset_dtree_YYYYMMDD_HHMMSS.parquet
‚îú‚îÄ‚îÄ variable_metadata.json         # Variable metadata
‚îî‚îÄ‚îÄ preprocessing_config.json      # Preprocessing configuration
```

### Key Features:
- **Timestamp Management**: All files saved with `YYYYMMDD_HHMMSS` format for version tracking
- **Automatic Cleanup**: Only latest model per type is kept (old versions auto-deleted)
- **Plot Organization**: Plots organized by section (eda, evaluation, explainability, training)
- **Model Organization**: Models organized by type in separate directories
- **Overwrite Logic**: Plots of same type/model are overwritten to avoid accumulation



## Quick Start

**Important**: The only required input is `DATASET_PATH` (path to your CSV/Parquet dataset). No other paths should be hardcoded.

## Instalaci√≥n r√°pida (Windows PowerShell)

1) Crear entorno

```powershell
# Opci√≥n Conda
conda env create -f environment.yml; conda activate mortality-ami-env

# Opci√≥n venv (Python)
python -m venv .venv; .\.venv\Scripts\Activate.ps1; pip install -r requirements.txt
```

Nota sobre PyTorch/torchvision (opcional):
- La red neuronal en `src/models.py` es opcional y est√° desactivada por defecto. Si no la vas a usar, no necesitas instalar `torch`/`torchvision`.
- En Windows, instala PyTorch desde el √≠ndice oficial para evitar errores como: `ERROR: No matching distribution found for torchvision`.

Instalaci√≥n PyTorch en Windows (elige una):

```powershell
# CPU-only
pip install --extra-index-url https://download.pytorch.org/whl/cpu torch torchvision

# CUDA 12.1 (si cuentas con drivers/CUDA compatibles)
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision

# Extras opcionales
pip install pytorch-lightning captum
```

Para activar el modelo de red neuronal en los experimentos, define:

```powershell
$env:ENABLE_TORCH_MODEL = "1"
```

2) Definir DATASET_PATH (ejemplo)

```powershell
$env:DATASET_PATH = "C:\\data\\ami_dataset.csv"
```

3) Ejecutar experimentos (entrenamiento + evaluaci√≥n)

```powershell
# Script PowerShell
.\u200brun_experiments.ps1 -Data $env:DATASET_PATH

# (Opcional en Linux/macOS)
# export DATASET_PATH="/ruta/ami_dataset.csv"
# bash run_experiments.sh
```

4) Lanzar el dashboard en Streamlit

```powershell
streamlit run streamlit_app.py -- --data $env:DATASET_PATH
```

5) Ejecutar pruebas unitarias

```powershell
pytest -q
```

## Estructura del proyecto

- `src/` c√≥digo modular:
	- `config.py`: configuraci√≥n global (incluye `DATASET_PATH`), semillas y nombres de columnas objetivo.
	- `data_load/`: utilidades de carga y gesti√≥n de archivos
		- `loaders.py`: carga de datos (CSV/Parquet/Feather)
		- `path_utils.py`: utilidades para gesti√≥n de rutas y archivos con timestamps
		- `splitters.py`: divisi√≥n de datos (estratificada o temporal)
	- `cleaning/`: m√≥dulos de limpieza de datos
		- `cleaner.py`: orquestador principal de limpieza
		- `imputation.py`, `encoding.py`, `discretization.py`, `outliers.py`: estrategias espec√≠ficas
	- `eda/`: an√°lisis exploratorio de datos con visualizaciones interactivas
	- `preprocessing/`: pipelines de preprocesamiento (imputaci√≥n, escalado, selecci√≥n)
	- `features.py`: utilidades para seleccionar columnas seguras (excluye identificadores/objetivos).
	- `models/`: definiciones de modelos (KNN, Logistic, Tree, XGBoost, LightGBM, Neural Network)
	- `training/`: entrenamiento con validaci√≥n cruzada anidada, RandomizedSearchCV, SMOTE, logging MLflow
	- `evaluation/`: m√©tricas (AUROC, AUPRC, etc.), curvas de calibraci√≥n, Decision Curve Analysis
	- `explainability/`: SHAP, importancia por permutaci√≥n, PDP
	- `prediction/`: recarga modelos y genera predicciones por lotes
	- `scoring/`: c√°lculo de scores cl√≠nicos (GRACE, TIMI)
- `dashboard/`: aplicaci√≥n Streamlit multi-p√°gina
	- `pages/`: p√°ginas individuales para limpieza, entrenamiento, evaluaci√≥n, explicabilidad
	- `app/`: configuraci√≥n, estado y utilidades UI
- `notebooks/`: an√°lisis interactivos en Jupyter
	- `eda.ipynb`: EDA completo con visualizaciones
	- `modeling.ipynb`: entrenamiento r√°pido de modelos base
	- `explainability.ipynb`: an√°lisis SHAP global
- `processed/`: **NUEVO - todos los outputs organizados**
	- `cleaned_datasets/`: datasets limpios con timestamps
	- `plots/`: visualizaciones organizadas por secci√≥n
	- `models/`: modelos entrenados organizados por tipo
	- `variable_metadata.json`: metadatos de variables
- `tests/`: pruebas con pytest (carga/preproceso, entrenamiento, guardado/carga de modelo)
- `run_experiments.ps1` y `run_experiments.sh`: scripts para ejecutar experimentos
- `.github/workflows/ci.yml`: integraci√≥n continua

**Nota**: Los directorios `reports/`, `dashboard/DATA/`, `dashboard/models/` y `Tools/models/` son legacy y ser√°n eliminados. Usa `processed/` para todos los nuevos outputs.

## C√≥mo entrenar y evaluar

Entrenamiento (validaci√≥n cruzada anidada + b√∫squeda aleatoria de hiperpar√°metros):

```powershell
python -m src.train --data $env:DATASET_PATH --task mortality
python -m src.train --data $env:DATASET_PATH --task arrhythmia
# Si tienes una columna continua (p.ej. estancia):
python -m src.train --data $env:DATASET_PATH --task regression
```

- Usa `--quick` para una ejecuci√≥n r√°pida de depuraci√≥n.
- Los mejores modelos se guardan en `models/` y el conjunto de test en `models/testset_*.parquet`.

Evaluaci√≥n (hold-out):

```powershell
python -m src.evaluate --data $env:DATASET_PATH --task mortality
```

Salidas: `reports/final_metrics_mortality.csv`, `reports/final_evaluation.pdf` y figuras en `reports/figures/`.

## Dashboard (Streamlit)

- Cargar o seleccionar un paciente (fila), mostrar probabilidad predicha, contribuciones globales (SHAP) y an√°lisis "what-if" para variables num√©ricas.
- Ejecuta:

```powershell
streamlit run streamlit_app.py -- --data $env:DATASET_PATH
```

## Predicci√≥n por lotes

```powershell
python -m src.predict --model .\models\best_classifier_mortality.joblib --input .\mis_pacientes.csv --output .\predicciones.csv
```

## Seguimiento de experimentos (opcional, MLflow)

Define las variables para activar el logging:

```powershell
$env:EXPERIMENT_TRACKER = "mlflow"
$env:TRACKING_URI = "http://localhost:5000"   # o ruta de tracking
```

## DATASET_PATH (√∫nica fuente de datos)

- Debe apuntar al fichero CSV/Parquet del dataset.
- Config√∫ralo v√≠a variable de entorno o p√°salo por `--data` en CLI/Streamlit.
- Ejemplo: `C:\\data\\ami_dataset.csv`.

## Consideraciones de privacidad

- No se registran ni se muestran identificadores directos de pacientes.
- Si tu dataset incluye IDs (patient_id, MRN), evita usarlos como features y no los vuelques en logs/figuras.

## Reproducibilidad

- Semilla fija
- Validaci√≥n cruzada estratificada y hold-out final
- Pipelines y modelos guardados en `models/` y reutilizables

## Resoluci√≥n de problemas

- Dependencias opcionales: si ves errores de importaci√≥n de `imblearn`, `mlflow` o `shap`, aseg√∫rate de instalarlas (est√°n en `requirements.txt` y `environment.yml`).
- Columnas faltantes: el c√≥digo tolera columnas opcionales; si falta la columna objetivo configurada, se devolver√° un error claro.
- GPU/NN: si no hay CUDA, la red neuronal usa CPU autom√°ticamente.
