# Mortality AMI Predictor (Tools)

**Version 2.0 - Fully Modularized Architecture**

End-to-end ML project for predicting in-hospital mortality and ventricular arrhythmias in AMI patients. Features a professional, modular Python codebase, Jupyter notebooks, automated tests, and a Streamlit dashboard.

## üéâ What's New in v2.0

- ‚úÖ **Complete Modularization**: Transformed from 9 monolithic files into 10 specialized modules with 38+ focused files
- ‚úÖ **Professional Design**: Factory, Strategy, Builder, Singleton, and Adapter patterns
- ‚úÖ **Type Safety**: 100% type hints across all modules
- ‚úÖ **Extensibility**: Easy to add new models, strategies, and features via registry pattern
- ‚úÖ **Better Organization**: No file > 500 lines, average ~100 lines per file
- ‚úÖ **Comprehensive Documentation**: 4+ guides including architecture, migration, and structure docs

### üìö Documentation

- **[Quick Start Guide](src/README.md)** - Get started in 5 minutes
- **[Complete Modularization Summary](src/COMPLETE_MODULARIZATION_SUMMARY.md)** - Full overview of all modules
- **[Migration Guide](src/MIGRATION_GUIDE.md)** - How to migrate from v1.0 to v2.0
- **[Project Structure](src/PROJECT_STRUCTURE.md)** - Visual diagrams and architecture
- **[Modularization Guide](src/MODULARIZATION_GUIDE.md)** - Deep dive into design decisions

---

## Quick Start

**Important**: The only required input is `DATASET_PATH` (path to your CSV/Parquet dataset). No other paths should be hardcoded.

## Instalaci√≥n r√°pida (Windows PowerShell)

1) Crear entorno

```powershell
# Opci√≥n Conda
conda env create -f environment.yml; conda activate mortality-ami-env

# Opci√≥n venv (Python)
python -m venv .venv; .\.venv\Scripts\Activate.ps1; pip install -r requirements.txt
```

Nota sobre PyTorch/torchvision (opcional):
- La red neuronal en `src/models.py` es opcional y est√° desactivada por defecto. Si no la vas a usar, no necesitas instalar `torch`/`torchvision`.
- En Windows, instala PyTorch desde el √≠ndice oficial para evitar errores como: `ERROR: No matching distribution found for torchvision`.

Instalaci√≥n PyTorch en Windows (elige una):

```powershell
# CPU-only
pip install --extra-index-url https://download.pytorch.org/whl/cpu torch torchvision

# CUDA 12.1 (si cuentas con drivers/CUDA compatibles)
pip install --index-url https://download.pytorch.org/whl/cu121 torch torchvision

# Extras opcionales
pip install pytorch-lightning captum
```

Para activar el modelo de red neuronal en los experimentos, define:

```powershell
$env:ENABLE_TORCH_MODEL = "1"
```

2) Definir DATASET_PATH (ejemplo)

```powershell
$env:DATASET_PATH = "C:\\data\\ami_dataset.csv"
```

3) Ejecutar experimentos (entrenamiento + evaluaci√≥n)

```powershell
# Script PowerShell
.\u200brun_experiments.ps1 -Data $env:DATASET_PATH

# (Opcional en Linux/macOS)
# export DATASET_PATH="/ruta/ami_dataset.csv"
# bash run_experiments.sh
```

4) Lanzar el dashboard en Streamlit

```powershell
streamlit run streamlit_app.py -- --data $env:DATASET_PATH
```

5) Ejecutar pruebas unitarias

```powershell
pytest -q
```

## Estructura del proyecto

- `src/` c√≥digo modular:
	- `config.py`: configuraci√≥n global (incluye `DATASET_PATH`), semillas y nombres de columnas objetivo.
	- `data.py`: carga de datos (CSV/Parquet/Feather), resumen EDA, gr√°ficos y split (estratificado o temporal).
	- `preprocess.py`: imputaci√≥n (IterativeImputer/KNNImputer), codificaci√≥n One-Hot, escalado, selecci√≥n opcional de variables.
	- `features.py`: utilidades para seleccionar columnas seguras (excluye identificadores/objetivos).
	- `models.py`: modelos KNN, Regresi√≥n Log√≠stica (L1/L2 + calibraci√≥n), √Årbol de Decisi√≥n, XGBoost, LightGBM, Red Neuronal (PyTorch con focal loss opcional), KMeans y Regresi√≥n Lineal.
	- `train.py`: validaci√≥n cruzada anidada, RandomizedSearchCV, SMOTE (si disponible), logging en MLflow (opcional), y guardado de artefactos.
	- `evaluate.py`: m√©tricas (AUROC, AUPRC, Accuracy, Precision, Recall, F1, Brier), curvas de calibraci√≥n, Decision Curve Analysis, matriz de confusi√≥n, comparaci√≥n con GRACE/TIMI (si existen columnas), perfiles KMeans y `final_evaluation.pdf`.
	- `explain.py`: explicabilidad global/local con SHAP (importaci√≥n perezosa), importancia por permutaci√≥n y PDP.
	- `predict.py`: recarga un modelo guardado y genera predicciones por lotes.
- `notebooks/`:
	- `eda.ipynb`: EDA (res√∫menes, faltantes, correlaciones, distribuci√≥n del objetivo) y guarda gr√°ficos en `reports/figures/`.
	- `modeling.ipynb`: entrenamiento r√°pido de un modelo base.
	- `explainability.ipynb`: resumen SHAP global del mejor modelo.
- `reports/`: figuras y `final_evaluation.pdf` tras evaluar.
- `models/`: artefactos guardados (`.joblib`) y el conjunto de test hold-out (`.parquet`).
- `tests/`: pruebas con pytest (carga/preproceso, entrenamiento r√°pido, guardado/carga de modelo).
- `run_experiments.ps1` y `run_experiments.sh`: scripts para ejecutar experimentos y registrar m√©tricas (MLflow opcional).
- `.github/workflows/ci.yml`: skeleton de CI (instala dependencias y corre pruebas).

## C√≥mo entrenar y evaluar

Entrenamiento (validaci√≥n cruzada anidada + b√∫squeda aleatoria de hiperpar√°metros):

```powershell
python -m src.train --data $env:DATASET_PATH --task mortality
python -m src.train --data $env:DATASET_PATH --task arrhythmia
# Si tienes una columna continua (p.ej. estancia):
python -m src.train --data $env:DATASET_PATH --task regression
```

- Usa `--quick` para una ejecuci√≥n r√°pida de depuraci√≥n.
- Los mejores modelos se guardan en `models/` y el conjunto de test en `models/testset_*.parquet`.

Evaluaci√≥n (hold-out):

```powershell
python -m src.evaluate --data $env:DATASET_PATH --task mortality
```

Salidas: `reports/final_metrics_mortality.csv`, `reports/final_evaluation.pdf` y figuras en `reports/figures/`.

## Dashboard (Streamlit)

- Cargar o seleccionar un paciente (fila), mostrar probabilidad predicha, contribuciones globales (SHAP) y an√°lisis "what-if" para variables num√©ricas.
- Ejecuta:

```powershell
streamlit run streamlit_app.py -- --data $env:DATASET_PATH
```

## Predicci√≥n por lotes

```powershell
python -m src.predict --model .\models\best_classifier_mortality.joblib --input .\mis_pacientes.csv --output .\predicciones.csv
```

## Seguimiento de experimentos (opcional, MLflow)

Define las variables para activar el logging:

```powershell
$env:EXPERIMENT_TRACKER = "mlflow"
$env:TRACKING_URI = "http://localhost:5000"   # o ruta de tracking
```

## DATASET_PATH (√∫nica fuente de datos)

- Debe apuntar al fichero CSV/Parquet del dataset.
- Config√∫ralo v√≠a variable de entorno o p√°salo por `--data` en CLI/Streamlit.
- Ejemplo: `C:\\data\\ami_dataset.csv`.

## Consideraciones de privacidad

- No se registran ni se muestran identificadores directos de pacientes.
- Si tu dataset incluye IDs (patient_id, MRN), evita usarlos como features y no los vuelques en logs/figuras.

## Reproducibilidad

- Semilla fija
- Validaci√≥n cruzada estratificada y hold-out final
- Pipelines y modelos guardados en `models/` y reutilizables

## Resoluci√≥n de problemas

- Dependencias opcionales: si ves errores de importaci√≥n de `imblearn`, `mlflow` o `shap`, aseg√∫rate de instalarlas (est√°n en `requirements.txt` y `environment.yml`).
- Columnas faltantes: el c√≥digo tolera columnas opcionales; si falta la columna objetivo configurada, se devolver√° un error claro.
- GPU/NN: si no hay CUDA, la red neuronal usa CPU autom√°ticamente.
