"""Explainability and SHAP Analysis page."""
from __future__ import annotations

import sys
from pathlib import Path

# Add parent directories to path
root_dir = Path(__file__).parents[2]
if str(root_dir) not in sys.path:
    sys.path.insert(0, str(root_dir))

import joblib
import numpy as np
import streamlit as st

from app import (
    initialize_state,
    list_saved_models,
)
from src.config import CONFIG
from src.explainability import (
    compute_shap_values,
    plot_shap_beeswarm,
    plot_shap_bar,
    plot_shap_waterfall,
    plot_shap_force,
    get_feature_importance,
    get_sample_shap_values,
)

# Initialize
initialize_state()

# Page config
st.title("üîç Model Explainability")
st.markdown("---")

# Check if data has been loaded
cleaned_data = st.session_state.get('cleaned_data')
raw_data = st.session_state.get('raw_data')

if cleaned_data is not None:
    df = cleaned_data
    st.success("‚úÖ Usando datos limpios")
elif raw_data is not None:
    df = raw_data
    st.warning("‚ö†Ô∏è Usando datos crudos")
else:
    st.warning("‚ö†Ô∏è No hay datos cargados. Por favor, carga un dataset en la p√°gina **üßπ Data Cleaning and EDA** primero.")
    st.stop()

# Get task from session state
task = st.session_state.get('target_column', 'mortality')
if task == 'exitus':
    task = 'mortality'

# Model selection
st.sidebar.markdown("---")
st.sidebar.header("üéØ Model Selection")

saved_models = list_saved_models(task)

if not saved_models:
    st.error(f"‚ùå No trained models found for task '{task}'. Please train models first.")
    st.stop()

selected_model_name = st.sidebar.selectbox(
    "Choose Model",
    list(saved_models.keys()),
    help="Select a trained model for explainability analysis"
)

model_path = saved_models[selected_model_name]

# SHAP settings
st.sidebar.markdown("---")
st.sidebar.header("‚öôÔ∏è SHAP Settings")

n_samples = st.sidebar.slider(
    "Number of samples",
    min_value=50,
    max_value=500,
    value=200,
    step=50,
    help="Number of samples to use for SHAP analysis"
)

# Load model
try:
    model = joblib.load(model_path)
    st.success(f"‚úÖ Model loaded: {selected_model_name}")
except Exception as e:
    st.error(f"‚ùå Error loading model: {e}")
    st.stop()

# Get feature columns
target_col = CONFIG.target_column if task == "mortality" else CONFIG.arrhythmia_column
feature_cols = [c for c in df.columns if c not in {CONFIG.target_column, CONFIG.arrhythmia_column}]

# Sample data for SHAP
sample_df = df[feature_cols].iloc[:n_samples]

st.markdown("---")

# Check if SHAP is available
try:
    import shap
    shap_available = True
except ImportError:
    shap_available = False
    st.error("‚ùå SHAP not installed. Please install it with: `pip install shap`")
    st.stop()

# SHAP analysis
st.subheader("SHAP Analysis")
st.caption(f"Using {len(sample_df)} samples for explainability")

if st.button("üöÄ Compute SHAP Values", type="primary", width='stretch'):
    try:
        with st.spinner("Computing SHAP values... This may take a moment"):
            # Compute SHAP values using the explainability module
            explainer, shap_explanation = compute_shap_values(
                model=model,
                X=sample_df,
                feature_names=feature_cols,
                max_samples=n_samples
            )
            
            # Store in session state
            st.session_state.shap_explainer = explainer
            st.session_state.shap_values = shap_explanation
            
            st.success("‚úÖ SHAP values computed successfully!")
    
    except Exception as e:
        st.error(f"‚ùå Error computing SHAP values: {e}")
        st.exception(e)

# Display SHAP plots if available
if "shap_values" in st.session_state and st.session_state.shap_values is not None:
    shap_values = st.session_state.shap_values
    
    st.markdown("---")
    
    # Tabs for different visualizations
    tab1, tab2, tab3, tab4 = st.tabs([
        "üìä Beeswarm Plot",
        "üìà Bar Plot",
        "üéØ Force Plot",
        "üåä Waterfall Plot"
    ])
    
    with tab1:
        st.markdown("### Beeswarm Plot")
        st.caption("Shows the distribution of SHAP values for each feature across all samples")
        
        try:
            fig = plot_shap_beeswarm(shap_values, max_display=20)
            st.pyplot(fig)
        
        except Exception as e:
            st.error(f"Error creating beeswarm plot: {e}")
    
    with tab2:
        st.markdown("### Feature Importance (Bar Plot)")
        st.caption("Mean absolute SHAP value for each feature")
        
        try:
            fig = plot_shap_bar(shap_values, max_display=20)
            st.pyplot(fig)
        
        except Exception as e:
            st.error(f"Error creating bar plot: {e}")
    
    with tab3:
        st.markdown("### Force Plot")
        st.caption("Visualize predictions for individual samples")
        
        sample_idx = st.slider(
            "Select sample index",
            min_value=0,
            max_value=len(shap_values) - 1,
            value=0
        )
        
        try:
            fig = plot_shap_force(shap_values, sample_idx=sample_idx)
            st.pyplot(fig)
        
        except Exception as e:
            st.error(f"Error creating force plot: {e}")
            # Try alternative visualization
            try:
                st.write("SHAP values for this sample:")
                shap_df = get_sample_shap_values(shap_values, sample_idx=sample_idx)
                st.dataframe(shap_df, use_container_width=True)
            except Exception as e2:
                st.error(f"Error showing alternative view: {e2}")
    
    with tab4:
        st.markdown("### Waterfall Plot")
        st.caption("Shows how each feature contributes to push the model output from the base value")
        
        sample_idx = st.slider(
            "Select sample index",
            min_value=0,
            max_value=len(shap_values) - 1,
            value=0,
            key="waterfall_slider"
        )
        
        try:
            fig = plot_shap_waterfall(shap_values, sample_idx=sample_idx)
            st.pyplot(fig)
        
        except Exception as e:
            st.error(f"Error creating waterfall plot: {e}")
    
    # Additional analysis
    st.markdown("---")
    
    with st.expander("üî¢ Feature Importance Rankings"):
        try:
            importance_df = get_feature_importance(shap_values)
            
            st.dataframe(
                importance_df.style.format({"Mean |SHAP|": "{:.6f}"}),
                use_container_width=True,
                hide_index=True
            )
        
        except Exception as e:
            st.error(f"Error computing feature importance: {e}")
    
    with st.expander("‚ÑπÔ∏è About SHAP"):
        st.markdown("""
        **SHAP (SHapley Additive exPlanations)**
        
        SHAP values explain the contribution of each feature to individual predictions:
        
        - **Positive SHAP value**: Feature pushes prediction higher
        - **Negative SHAP value**: Feature pushes prediction lower
        - **Magnitude**: Importance of the feature for that prediction
        
        **Visualizations:**
        - **Beeswarm**: Overall feature importance and value distribution
        - **Bar**: Simple feature importance ranking
        - **Force**: Individual prediction explanation
        - **Waterfall**: Step-by-step contribution breakdown
        
        SHAP values are based on game theory and provide consistent, locally accurate explanations.
        """)

else:
    st.info("üëÜ Click 'Compute SHAP Values' to generate explainability visualizations")

