"""Model Training page."""
from __future__ import annotations

import sys
from pathlib import Path

# Add parent directories to path
root_dir = Path(__file__).parents[2]
if str(root_dir) not in sys.path:
    sys.path.insert(0, str(root_dir))

import streamlit as st

from app import (
    display_model_list,
    get_state,
    initialize_state,
    set_state,
    sidebar_training_controls,
    train_models_with_progress,
)

# Initialize
initialize_state()

# Page config
st.title("ğŸ¤– Model Training")
st.markdown("---")

# Check if data has been loaded
cleaned_data = st.session_state.get('cleaned_data')
raw_data = st.session_state.get('raw_data')

if cleaned_data is not None:
    df = cleaned_data
    data_path = st.session_state.get('data_path')
    st.success("âœ… Usando datos limpios del proceso de limpieza")
elif raw_data is not None:
    df = raw_data
    data_path = st.session_state.get('data_path')
    st.warning("âš ï¸ Usando datos crudos (se recomienda limpiar primero)")
else:
    st.warning("âš ï¸ No hay datos cargados. Por favor, carga un dataset en la pÃ¡gina **ğŸ§¹ Data Cleaning and EDA** primero.")
    st.stop()

# Si no hay data_path o el path no existe, crear un archivo temporal
import tempfile
if not data_path or not Path(data_path).exists():
    st.info("â„¹ï¸ Guardando datos en archivo temporal para el entrenamiento...")
    temp_dir = Path(tempfile.gettempdir())
    data_path = temp_dir / "streamlit_training_dataset.csv"
    df.to_csv(data_path, index=False)
    st.session_state.data_path = str(data_path)
    st.success(f"âœ… Dataset guardado en: {data_path}")

# Get task from session state
task = st.session_state.get('target_column', 'mortality')
if task == 'exitus':
    task = 'mortality'

# Training settings
st.sidebar.markdown("---")
st.sidebar.header("âš™ï¸ Training Configuration")

# Info about the rigorous pipeline (always active)
st.sidebar.info("""
ğŸ“ **Pipeline Riguroso Activo**

Este dashboard SIEMPRE usa el pipeline acadÃ©mico completo:
â€¢ âœ… ValidaciÃ³n cruzada estratificada repetida (â‰¥30 corridas)
â€¢ âœ… Curvas de aprendizaje
â€¢ âœ… ComparaciÃ³n estadÃ­stica (Shapiro-Wilk, t-test/Mann-Whitney)

La evaluaciÃ³n final (Bootstrap/Jackknife) se hace en el mÃ³dulo de **EvaluaciÃ³n**.
""")

quick, imputer_mode, selected_models = sidebar_training_controls()

# Main content
st.subheader("Training Configuration")

col1, col2 = st.columns(2)

with col1:
    st.metric("Task", task.capitalize())
    st.metric("Imputation", imputer_mode.capitalize())

with col2:
    st.metric("Quick Mode", "Enabled" if quick else "Disabled")
    st.metric("Models Selected", len(selected_models))

# Display selected models
if selected_models:
    st.info(f"ğŸ“¦ Selected models: {', '.join(selected_models)}")
else:
    st.warning("âš ï¸ No models selected for training")

st.markdown("---")

# Training section
st.subheader("Train Models")

if not selected_models:
    st.error("âŒ Please select at least one model from the sidebar")
else:
    # Show pipeline info (always rigorous)
    st.info("""
    ### ğŸ“ Pipeline de ExperimentaciÃ³n Riguroso
    
    Este pipeline seguirÃ¡ las mejores prÃ¡cticas acadÃ©micas:
    
    **FASE 1: Train + Validation**
    - âœ… ValidaciÃ³n cruzada estratificada repetida (30+ corridas)
    - âœ… EstimaciÃ³n de Î¼ (media) y Ïƒ (desviaciÃ³n) por modelo
    - âœ… Curvas de aprendizaje para diagnÃ³stico
    
    **FASE 3: ComparaciÃ³n EstadÃ­stica**
    - âœ… Prueba de normalidad (Shapiro-Wilk)
    - âœ… Test paramÃ©trico (t-Student) o no paramÃ©trico (Mann-Whitney)
    - âœ… TamaÃ±o del efecto (Cohen's d)
    
    **FASE 2: Test (Estimado Final)**
    - âš ï¸ Se realizarÃ¡ en el mÃ³dulo de **EvaluaciÃ³n**
    - Bootstrap (1000 iteraciones con reemplazo)
    - Jackknife (eliminando 1 elemento)
    - Intervalos de confianza al 95%
    
    ğŸ“Š Se generarÃ¡n grÃ¡ficos y reportes detallados en `models/`
    """)
    
    if st.button("ğŸš€ Start Training", type="primary", width='stretch'):
        try:
            with st.spinner("Training models..."):
                save_paths = train_models_with_progress(
                    data_path=data_path,
                    task=task,
                    quick=quick,
                    imputer_mode=imputer_mode,
                    selected_models=selected_models,
                )
            
            # Update session state
            set_state("is_trained", True)
            set_state("last_train_task", task)
            set_state("last_train_models", list(save_paths.keys()))
            
            st.success(f"âœ… Successfully trained {len(save_paths)} model(s)")
            
            # Display saved models
            with st.expander("View saved model paths"):
                for name, path in save_paths.items():
                    st.code(f"{name}: {path}", language="text")
        
        except FileNotFoundError as e:
            st.error(f"âŒ Dataset file not found: {e}")
        except Exception as e:
            st.error(f"âŒ Error during training: {e}")
            st.exception(e)

st.markdown("---")

# Display saved models section
st.subheader("Saved Models")

last_task = get_state("last_train_task")
if last_task and last_task != task:
    st.info(f"â„¹ï¸ Last training was for task: {last_task}")

display_model_list(task)

# Training history/log
with st.expander("â„¹ï¸ Training Notes"):
    st.markdown("""
    ### âš™ï¸ ConfiguraciÃ³n del Entrenamiento
    
    **Quick Mode:**
    - âœ… BÃºsqueda simplificada de hiperparÃ¡metros
    - âœ… Menos splits en CV (3Ã—3 = 9 corridas en vez de 10Ã—10 = 100)
    - âœ… IteraciÃ³n rÃ¡pida para depuraciÃ³n
    - âš ï¸ Recomendado solo para exploraciÃ³n inicial
    
    **Estrategias de ImputaciÃ³n:**
    - **Iterative**: IterativeImputer de sklearn (MICE - Multiple Imputation by Chained Equations)
    - **KNN**: K-Nearest Neighbors imputation (busca valores similares)
    - **Simple**: ImputaciÃ³n bÃ¡sica (media/mediana/moda)
    
    **Tipos de Modelos Disponibles:**
    - ğŸŒ³ Decision Trees, Random Forest
    - ğŸš€ XGBoost (Gradient Boosting)
    - ğŸ“ˆ Logistic Regression
    - ğŸ¯ Support Vector Machine (SVM)
    - ğŸ‘¥ K-Nearest Neighbors (KNN)
    - ğŸ“Š Naive Bayes
    
    ### ğŸ“‹ Pipeline de ExperimentaciÃ³n
    
    El **Pipeline Riguroso** implementa el proceso cientÃ­fico completo:
    
    1. **ValidaciÃ³n Cruzada Estratificada Repetida**: Se entrena y evalÃºa cada modelo
       mÃºltiples veces (â‰¥30 corridas) para obtener estimaciones robustas de Î¼ y Ïƒ.
       
    2. **Curvas de Aprendizaje**: Diagnostican sobreajuste/subajuste y la necesidad
       de mÃ¡s datos.
       
    3. **ComparaciÃ³n EstadÃ­stica**: Determina si las diferencias entre modelos son
       estadÃ­sticamente significativas usando:
       - Prueba de normalidad (Shapiro-Wilk)
       - Test paramÃ©trico (t-Student) si los datos son normales
       - Test no paramÃ©trico (Mann-Whitney) si no lo son
       
    4. **EvaluaciÃ³n Final en Test Set**: Una vez seleccionado el mejor modelo:
       - Bootstrap (1000 iteraciones con reemplazo)
       - Jackknife (leave-one-out)
       - Intervalos de confianza al 95%
    
    ğŸ“š Ver documentaciÃ³n completa en `Tools/docs/EXPERIMENT_PIPELINE.md`
    """)
