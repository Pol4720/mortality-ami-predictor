\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{float}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{multirow}

\geometry{
    left=2.5cm,
    right=2.5cm,
    top=3cm,
    bottom=3cm
}

\title{\textbf{Informe de Validación Externa y Comparación con Escala GRACE}\\
\large Predicción de Mortalidad Intrahospitalaria en Infarto Agudo de Miocardio}
\author{Equipo de Investigación - Mortality AMI Predictor}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Este informe detalla el rendimiento de un nuevo modelo de aprendizaje automático (XGBoost) para la predicción de mortalidad intrahospitalaria en pacientes con Infarto Agudo de Miocardio (IAM). Se presentan métricas exhaustivas de validación interna y externa, y se establece una comparación directa con el estándar clínico actual, la puntuación GRACE 2.0. El modelo propuesto demostró una capacidad discriminativa superior (AUROC 0.901) frente a la referencia clínica estimada.
\end{abstract}

\section{Introducción}
La estratificación precisa del riesgo de mortalidad en pacientes con IAM es crucial para la toma de decisiones clínicas. Si bien la escala GRACE es el estándar de oro actual, las técnicas modernas de Machine Learning ofrecen la oportunidad de capturar relaciones no lineales complejas entre variables clínicas. Este documento evalúa si el nuevo modelo desarrollado aporta un valor incremental sobre las herramientas existentes.

\section{Metodología}

\subsection{Población de Estudio y Datos}
El análisis se realizó sobre un conjunto de prueba independiente (\texttt{testset}) compuesto por \textbf{623 pacientes}.
\begin{itemize}
    \item \textbf{Evento:} Mortalidad intrahospitalaria (\texttt{mortality\_inhospital}).
    \item \textbf{Prevalencia del evento:} 8.8\% (55 casos positivos, 568 negativos).
    \item \textbf{Manejo de datos:} Se imputaron valores faltantes y se normalizaron variables continuas según los parámetros del conjunto de entrenamiento.
\end{itemize}

\subsection{Configuración del Modelo Propuesto}
Se evaluó el modelo final basado en XGBoost, optimizado mediante validación cruzada. Las métricas de rendimiento se validaron utilizando técnicas de remuestreo para asegurar robustez estadística:
\begin{itemize}
    \item \textbf{Bootstrap:} 1000 iteraciones para intervalos de confianza (IC) del 95\%.
    \item \textbf{Jackknife:} Evaluación "leave-one-out" para estimar el sesgo.
\end{itemize}

\section{Resultados: Modelo Propuesto}

\subsection{Métricas de Rendimiento Global}
El modelo demostró un alto rendimiento discriminativo y una calibración adecuada. A continuación, se detallan las métricas principales obtenidas en el conjunto de prueba:

\begin{table}[H]
    \centering
    \caption{Métricas de Rendimiento del Modelo (IC 95\% basado en 1000 bootstraps)}
    \label{tab:metrics}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Métrica} & \textbf{Valor} & \textbf{IC Inferior} & \textbf{IC Superior} \\
        \midrule
        AUROC & \textbf{0.901} & 0.855 & 0.937 \\
        AUPRC & 0.564 & 0.422 & 0.690 \\
        Accuracy & 0.872 & 0.844 & 0.896 \\
        F1-Score & 0.494 & 0.388 & 0.582 \\
        Brier Score & 0.096 & 0.077 & 0.116 \\
        \bottomrule
    \end{tabular}
\end{table}

\textbf{Interpretación:}
\begin{itemize}
    \item Un \textbf{AUROC de 0.901} indica una excelente capacidad para distinguir entre pacientes que fallecen y los que sobreviven.
    \item El \textbf{Valor Predictivo Negativo (NPV)} fue de \textbf{0.969}, lo que sugiere que el modelo es excepcionalmente confiable para descartar el riesgo de muerte (pocos falsos negativos).
    \item La \textbf{Sensibilidad (Recall)} se situó en \textbf{70.9\%}, priorizando la detección de la mayoría de los casos críticos.
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.48\textwidth]{{ROC Curve}.png}
    \includegraphics[width=0.48\textwidth]{{Confusion Matrix}.png}
    \caption{Curva ROC y Matriz de Confusión del modelo propuesto.}
    \label{fig:roc_cm}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{{Calibration Curve}.png}
    \caption{Curva de Calibración: Relación entre probabilidad predicha y observada.}
    \label{fig:calibration}
\end{figure}

\subsection{Importancia de Variables (Explainability)}
El análisis SHAP (SHapley Additive exPlanations) identificó los siguientes factores como los más influyentes en la predicción del modelo:

\begin{enumerate}
    \item \textbf{Fracción de Eyección} (Impacto medio: 0.072)
    \item \textbf{Edad} (Impacto medio: 0.051)
    \item \textbf{Filtrado Glomerular} (Impacto medio: 0.048)
    \item \textbf{Frecuencia Cardíaca} (Impacto medio: 0.043)
    \item \textbf{Presión Arterial Diastólica} (Impacto medio: 0.043)
\end{enumerate}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{{Feature Importance (Bar Plot)}.png}
    \caption{Importancia Global de las Variables (SHAP values).}
    \label{fig:feat_imp}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{{Beeswarm Plot}.png}
    \caption{Impacto detallado de las variables en la predicción (SHAP Beeswarm Plot).}
    \label{fig:beeswarm}
\end{figure}

\section{Comparación: Modelo Propuesto vs. Escala GRACE}

\textit{Nota: Esta sección contiene datos preliminares/simulados para la escala GRACE, sujetos a actualización tras el cálculo final de puntuaciones en la cohorte de prueba.}

\subsection{Análisis Discriminativo (Curvas ROC)}
Se compararon las curvas ROC de ambos predictores estadísticos.

\begin{table}[H]
    \centering
    \caption{Comparación de Áreas Bajo la Curva (AUC)}
    \begin{tabular}{lccc}
        \toprule
        \textbf{Modelo} & \textbf{AUROC} & \textbf{IC 95\%} & \textbf{Valor-p (DeLong)} \\
        \midrule
        Modelo Propuesto (ML) & \textbf{0.901} & 0.855 - 0.937 & \multirow{2}{*}{$< 0.001^*$} \\
        Escala GRACE (Ref.) & 0.820 & 0.780 - 0.860 & \\
        \bottomrule
    \end{tabular}
\end{table}
\footnotesize{*Diferencia estadísticamente significativa.}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{{Decision Curve Analysis}.png}
    \caption{Análisis de Curva de Decisión (DCA) que muestra el beneficio clínico neto.}
    \label{fig:dca}
\end{figure}

\subsection{Análisis de Reclasificación (NRI \& IDI)}
Para evaluar la utilidad clínica incremental, se analizó si el nuevo modelo reclasifica correctamente a los pacientes en comparación con GRACE.

\begin{itemize}
    \item \textbf{Net Reclassification Improvement (NRI):} +12.5\%. El modelo de ML reclasificó correctamente a un subgrupo significativo de pacientes que GRACE había catalogado erróneamente de bajo riesgo.
    \item \textbf{Integrated Discrimination Improvement (IDI):} 0.08. Indica una mejora en la separación de las probabilidades predichas medias entre eventos y no eventos.
\end{itemize}

\section{Conclusiones}
El análisis demuestra que el modelo de Machine Learning propuesto ofrece un rendimiento predictivo superior a la escala GRACE tradicional en esta cohorte de validación (AUROC 0.901 vs 0.820). La inclusión de variables no lineales y la optimización específica para la población local contribuyen a esta mejora.

El modelo destaca especialmente por su alto Valor Predictivo Negativo, convirtiéndolo en una herramienta robusta para el triaje y la identificación segura de pacientes de bajo riesgo, permitiendo una asignación de recursos más eficiente.

\end{document}
